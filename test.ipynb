{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab86b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 10:31:55.500893: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-27 10:32:01.808058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stellargraph import StellarGraph\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "import json\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph.mapper import HinSAGELinkGenerator\n",
    "from stellargraph.layer import HinSAGE, link_regression, link_classification\n",
    "from tensorflow.keras import Model, optimizers, losses, metrics\n",
    "\n",
    "import multiprocessing\n",
    "from stellargraph import datasets\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabb61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stellargraph import StellarGraph\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "import category_encoders as ce\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('./data/230106_frozen_metadata.csv.gz', low_memory=False)\n",
    "df = df.dropna(subset=['organism_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8fe8d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicate organism-molecule pair\n",
    "df_agg = df.groupby(['organism_name',\n",
    "                     'structure_smiles_2D']).size().reset_index(name='reference_wikidata')\n",
    "\n",
    "df_agg = df.groupby(['organism_name', 'structure_smiles_2D']).agg({\n",
    "    'reference_wikidata': 'size',\n",
    "    'organism_taxonomy_08genus': 'first',\n",
    "    'organism_taxonomy_06family': 'first',\n",
    "    'organism_taxonomy_05order': 'first',\n",
    "    'organism_taxonomy_04class': 'first',\n",
    "    'organism_taxonomy_03phylum': 'first',\n",
    "    'organism_taxonomy_02kingdom': 'first',\n",
    "    'organism_taxonomy_01domain': 'first',\n",
    "    'structure_taxonomy_classyfire_01kingdom': 'first',\n",
    "    'structure_taxonomy_classyfire_02superclass': 'first',\n",
    "    'structure_taxonomy_classyfire_03class': 'first',\n",
    "    'structure_taxonomy_classyfire_04directparent' : 'first'\n",
    "    # add other columns here as needed\n",
    "}).reset_index()\n",
    "\n",
    "df_agg['total_papers_molecule'] = df_agg.groupby(\n",
    "    'structure_smiles_2D')['reference_wikidata'].transform('sum')\n",
    "df_agg['total_papers_species'] = df_agg.groupby(\n",
    "    'organism_name')['reference_wikidata'].transform('sum')\n",
    "\n",
    "#get random subset of the database (comment to have the full DB)\n",
    "#df_agg = df_agg.sample(n=20000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb36c5d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_species_df = df_agg.drop_duplicates(subset=['organism_name'])\n",
    "species_features_df = unique_species_df[['organism_taxonomy_01domain', 'organism_taxonomy_02kingdom',\n",
    "          'organism_taxonomy_03phylum', 'organism_taxonomy_04class',\n",
    "         'organism_taxonomy_05order', 'organism_taxonomy_06family',\n",
    "         'organism_taxonomy_08genus', 'organism_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5152b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import hashlib\n",
    "\n",
    "# Initialize a LabelEncoder for each level of the taxonomy\n",
    "encoders = {col: LabelEncoder() for col in species_features_df.columns}\n",
    "\n",
    "# Create a new DataFrame to hold the encoded labels\n",
    "encoded_df = species_features_df.copy()\n",
    "\n",
    "# Encode each column, but concatenate the encoded labels as we go\n",
    "for col in species_features_df.columns:\n",
    "    # Apply the LabelEncoder for this column\n",
    "    encoded_labels = encoders[col].fit_transform(species_features_df[col])\n",
    "    \n",
    "    # Concatenate the encoded labels to the labels from the previous column\n",
    "    if col == 'organism_taxonomy_01domain':\n",
    "        encoded_df[col] = encoded_labels\n",
    "    else:\n",
    "        encoded_df[col] = encoded_df[prev_col].astype(str) + \"_\" + encoded_labels.astype(str)\n",
    "    \n",
    "    prev_col = col\n",
    "\n",
    "# Initialize a MinMaxScaler to scale the hashed values\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Now convert the encoded labels to floats by applying a hash function and then scaling\n",
    "for col in encoded_df.columns:\n",
    "    # Apply the hash function and convert to absolute values to avoid negative numbers\n",
    "    encoded_df[col] = [int(hashlib.md5(str(x).encode()).hexdigest(), 16) for x in encoded_df[col]]\n",
    "    \n",
    "    # Scale the hashed values to be between 0 and 1\n",
    "    encoded_df[col] = scaler.fit_transform(encoded_df[col].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6702ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_df.index = [i for i in species_features_df.organism_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7561849",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.to_csv(\"./data/species_features_encoded_with_hash.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "445c1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch unique species and molecules and their respective features\n",
    "unique_species_df = df_agg.drop_duplicates(subset=['organism_name'])\n",
    "unique_molecules_df = df_agg.drop_duplicates(subset=['structure_smiles_2D'])\n",
    "\n",
    "# Fetch the corresponding features\n",
    "species_features_df = unique_species_df[['organism_taxonomy_01domain', 'organism_taxonomy_02kingdom',\n",
    "          'organism_taxonomy_03phylum', 'organism_taxonomy_04class',\n",
    "         'organism_taxonomy_05order', 'organism_taxonomy_06family',\n",
    "         'organism_taxonomy_08genus', 'organism_name']]\n",
    "molecule_features_df = unique_molecules_df[['structure_taxonomy_classyfire_01kingdom',\n",
    "                                            'structure_taxonomy_classyfire_02superclass',\n",
    "                                            'structure_taxonomy_classyfire_03class',\n",
    "                                            'structure_taxonomy_classyfire_04directparent']]\n",
    "\n",
    "\n",
    "# create features\n",
    "encoder = ce.BinaryEncoder(cols=[col for col in species_features_df.columns])\n",
    "species_features_dummy = encoder.fit_transform(species_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "069d5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = ce.basen.BaseNEncoder(cols=[col for col in species_features_df.columns], base=len(species_features_df)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dae7a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = enc.fit_transform(species_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5780997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.index = [i for i in species_features_df.organism_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8810bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(\"./data/species_BaseNEncoder.csv.gz\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
